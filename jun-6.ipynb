{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "recall: three key motivations for medical RAG\n",
    "- evidence-based medicine\n",
    "- credibility and trust\n",
    "- dynamic knowledge updates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "document processing pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'fitz'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 7\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124;03mDocument processing service for RAG system\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03mHandles PDF extraction, text chunking, and preprocessing\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mfitz\u001b[39;00m \u001b[38;5;66;03m# PyMuPDF\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mre\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m List, Dict, Tuple\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'fitz'"
     ]
    }
   ],
   "source": [
    "\n",
    "\"\"\"\n",
    "Document processing service for RAG system\n",
    "Handles PDF extraction, text chunking, and preprocessing\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import fitz # PyMuPDF\n",
    "import re\n",
    "from typing import List, Dict, Tuple\n",
    "from pathlib import Path\n",
    "\n",
    "class DocumentProcessor:\n",
    "    def __init__(self, chunk_size: int = 1000, chunk_overlap: int = 200):\n",
    "        \"\"\"\n",
    "        Initialize document processor\n",
    "\n",
    "        Args:\n",
    "            chunk_size: Maximum size of each text chunk\n",
    "            chunk_overlap: Overlap between chunks for context preservation\n",
    "        \"\"\"\n",
    "        self.chunk_size = chunk_size\n",
    "        self.chunk_overlap = chunk_overlap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_text_from_pdf(self, pdf_path: str) -> str:\n",
    "    \"\"\"\n",
    "    Extract text from PDF file\n",
    "\n",
    "    Args:\n",
    "        pdf_path: Path to the PDF file\n",
    "\n",
    "    Returns:\n",
    "        Extracted text content\n",
    "    \"\"\"\n",
    "    try:\n",
    "        doc = fitz.open(pdf_path)\n",
    "        text = \"\"\n",
    "\n",
    "        for page_num in range(len(doc)):\n",
    "            page = doc[page_num]\n",
    "            text += page.get_text()\n",
    "\n",
    "        doc.close()\n",
    "        return text\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting text from {pdf_path}: {str(e)}\")\n",
    "        return \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def clean_text(self, text: str) -> str:\n",
    "    \"\"\"\n",
    "    Clean and preprocess extracted text\n",
    "\n",
    "    Args:\n",
    "        text: Raw extracted text\n",
    "\n",
    "    Returns:\n",
    "        Cleaned text\n",
    "    \"\"\"\n",
    "# Remove excessive whitespace\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "\n",
    "# Remove special characters but keep medical terminology\n",
    "    text = re.sub(r'[^\\w\\s\\-\\.\\,\\:\\;\\(\\)\\%\\+\\=\\<\\>]', '', text)\n",
    "\n",
    "# Remove page numbers and headers/footers patterns\n",
    "    text = re.sub(r'\\b\\d+\\s*$', '', text, flags=re.MULTILINE)\n",
    "\n",
    "# Remove excessive newlines\n",
    "    text = re.sub(r'\\n+', '\\n', text)\n",
    "\n",
    "    return text.strip()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "vector store service implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Vector store service for RAG system\n",
    "Handles embeddings generation, storage, and similarity search using FAISS\n",
    "\"\"\"\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "import requests\n",
    "from typing import List, Dict, Tuple, Optional\n",
    "\n",
    "class SimpleVectorStore:\n",
    "    def __init__(self, dimension: int = 1536):\n",
    "        \"\"\"\n",
    "        Initialize vector store\n",
    "\n",
    "        Args:\n",
    "            dimension: Dimension of embedding vectors (OpenAI embeddings are 1536)\n",
    "        \"\"\"\n",
    "        self.dimension = dimension\n",
    "        self.vectors = []\n",
    "        self.metadata = []\n",
    "        self.index_to_id = {}\n",
    "        self.next_id = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(self, query_vector: np.ndarray, k: int = 5) -> List[Tuple[Dict, float]]:\n",
    "    \"\"\"Search for similar vectors\"\"\"\n",
    "    if not self.vectors:\n",
    "        return []\n",
    "\n",
    "# Calculate cosine similarity\n",
    "    similarities = []\n",
    "    query_norm = np.linalg.norm(query_vector)\n",
    "\n",
    "    for i, vector in enumerate(self.vectors):\n",
    "        vector_norm = np.linalg.norm(vector)\n",
    "        if vector_norm == 0 or query_norm == 0:\n",
    "            similarity = 0\n",
    "        else:\n",
    "            similarity = np.dot(query_vector, vector) / (query_norm * vector_norm)\n",
    "        similarities.append((i, similarity))\n",
    "\n",
    "# Sort by similarity (descending)\n",
    "    similarities.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Return top k results\n",
    "    results = []\n",
    "    for i, (idx, score) in enumerate(similarities[:k]):\n",
    "        results.append((self.metadata[idx], score))\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_embeddings(self, texts: List[str]) -> List[List[float]]:\n",
    "    \"\"\"\n",
    "    Generate embeddings for list of texts using OpenAI API\n",
    "\n",
    "    Args:\n",
    "        texts: List of text strings to embed\n",
    "\n",
    "    Returns:\n",
    "        List of embedding vectors\n",
    "    \"\"\"\n",
    "    if not self.api_key:\n",
    "        raise ValueError(\"OpenAI API key not available\")\n",
    "\n",
    "    url = \"https://api.openai.com/v1/embeddings\"\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {self.api_key}\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "\n",
    "    all_embeddings = []\n",
    "    batch_size = 100  # OpenAI API limit\n",
    "\n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        batch_texts = texts[i:i + batch_size]\n",
    "\n",
    "        data = {\n",
    "            \"input\": batch_texts,\n",
    "            \"model\": \"text-embedding-ada-002\"\n",
    "        }\n",
    "\n",
    "        try:\n",
    "            response = requests.post(url, headers=headers, json=data)\n",
    "            response.raise_for_status()\n",
    "\n",
    "            result = response.json()\n",
    "            embeddings = [item[\"embedding\"] for item in result[\"data\"]]\n",
    "            all_embeddings.extend(embeddings)\n",
    "\n",
    "            print(f\"Generated embeddings for batch {i//batch_size + 1}/{(len(texts)-1)//batch_size + 1}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error generating embeddings for batch {i//batch_size + 1}: {e}\")\n",
    "            # Add zero vectors for failed batch\n",
    "            all_embeddings.extend([[0.0] * 1536 for _ in batch_texts])\n",
    "\n",
    "    return all_embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "building the complete RAG pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "RAG Service - Retrieval Augmented Generation\n",
    "Integrates document processing, vector search, and LLM generation\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "from typing import List, Dict, Optional\n",
    "from .document_processor import DocumentProcessor\n",
    "from .vector_store import VectorStoreService\n",
    "import requests\n",
    "import json\n",
    "\n",
    "class RAGService:\n",
    "    def __init__(self,\n",
    "                 documents_dir: str = \"rag_resources\",\n",
    "                 vector_store_path: str = \"medical_vector_store.json\",\n",
    "                 chunk_size: int = 1000,\n",
    "                 chunk_overlap: int = 200):\n",
    "        \"\"\"\n",
    "        Initialize RAG service\n",
    "\n",
    "        Args:\n",
    "            documents_dir: Directory containing medical documents\n",
    "            vector_store_path: Path to vector store file\n",
    "            chunk_size: Size of text chunks\n",
    "            chunk_overlap: Overlap between chunks\n",
    "        \"\"\"\n",
    "        self.documents_dir = documents_dir\n",
    "        self.doc_processor = DocumentProcessor(chunk_size, chunk_overlap)\n",
    "        self.vector_store = VectorStoreService(vector_store_path)\n",
    "        self.api_key = self._get_api_key()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def initialize_knowledge_base(self, force_rebuild: bool = False) -> bool:\n",
    "    \"\"\"\n",
    "    Initialize the medical knowledge base from documents\n",
    "\n",
    "    Args:\n",
    "        force_rebuild: Whether to rebuild even if vector store exists\n",
    "\n",
    "    Returns:\n",
    "        True if successful, False otherwise\n",
    "    \"\"\"\n",
    "# Check if vector store already exists and has content\n",
    "    store_info = self.vector_store.get_store_info()\n",
    "    if store_info['total_vectors'] > 0 and not force_rebuild:\n",
    "        print(f\"Knowledge base already initialized with {store_info['total_vectors']} vectors\")\n",
    "        print(f\"Sources: {store_info['sources']}\")\n",
    "        return True\n",
    "\n",
    "    print(\"Initializing medical knowledge base...\")\n",
    "\n",
    "# Check if documents directory exists\n",
    "    if not os.path.exists(self.documents_dir):\n",
    "        print(f\"Documents directory {self.documents_dir} not found!\")\n",
    "        return False\n",
    "\n",
    "    try:\n",
    "# Process all PDF documents\n",
    "        print(f\"Processing documents from {self.documents_dir}...\")\n",
    "        all_chunks = self.doc_processor.process_documents_directory(self.documents_dir)\n",
    "\n",
    "        if not all_chunks:\n",
    "            print(\"No documents were processed successfully!\")\n",
    "            return False\n",
    "\n",
    "# Filter for medical content\n",
    "        print(\"Filtering for medical content...\")\n",
    "        medical_chunks = self.doc_processor.filter_medical_content(all_chunks)\n",
    "\n",
    "        print(f\"Found {len(medical_chunks)} relevant medical text chunks\")\n",
    "\n",
    "        if not medical_chunks:\n",
    "            print(\"No relevant medical content found!\")\n",
    "            return False\n",
    "\n",
    "# Add to vector store\n",
    "        print(\"Adding documents to vector store...\")\n",
    "        self.vector_store.add_documents(medical_chunks)\n",
    "\n",
    "# Print summary\n",
    "        store_info = self.vector_store.get_store_info()\n",
    "        print(f\"\\nâœ… Knowledge base initialized successfully!\")\n",
    "        print(f\"Total vectors: {store_info['total_vectors']}\")\n",
    "        print(f\"Sources: {store_info['sources']}\")\n",
    "\n",
    "        return True\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error initializing knowledge base: {e}\")\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "enhanced medical analysis with RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def enhanced_medical_analysis(self,\n",
    "                            original_prompt: str,\n",
    "                            patient_context: str = \"\",\n",
    "                            prediction_results: Dict = None) -> str:\n",
    "    \"\"\"\n",
    "    Provide enhanced medical analysis using RAG\n",
    "\n",
    "    Args:\n",
    "        original_prompt: Original analysis prompt\n",
    "        patient_context: Patient information context\n",
    "        prediction_results: AI prediction results\n",
    "\n",
    "    Returns:\n",
    "        Enhanced analysis with medical literature support\n",
    "    \"\"\"\n",
    "    if not self.api_key:\n",
    "        return \"Error: OpenAI API key not available\"\n",
    "\n",
    "# Create search query for relevant literature\n",
    "    search_query = f\"diabetic retinopathy {original_prompt}\"\n",
    "    if prediction_results:\n",
    "        search_query += f\" grade {prediction_results.get('value', '')} {prediction_results.get('class', '')}\"\n",
    "\n",
    "# Get relevant medical context\n",
    "    medical_context = self.get_relevant_medical_context(search_query, max_context_length=2500)\n",
    "\n",
    "# Construct enhanced prompt\n",
    "    enhanced_prompt = f\"\"\"You are an expert ophthalmologist providing analysis based on current medical literature and best practices.\n",
    "\n",
    "{patient_context}\n",
    "\n",
    "RELEVANT MEDICAL LITERATURE:\n",
    "{medical_context}\n",
    "\n",
    "ORIGINAL ANALYSIS REQUEST:\n",
    "{original_prompt}\n",
    "\n",
    "Please provide a comprehensive analysis that:\n",
    "1. Incorporates insights from the relevant medical literature above\n",
    "2. Follows evidence-based best practices\n",
    "3. Cites specific findings from the literature when relevant\n",
    "4. Provides both technical medical assessment and patient-friendly explanation\n",
    "5. Includes appropriate recommendations based on current guidelines\n",
    "\n",
    "**IMPORTANT FORMATTING INSTRUCTIONS:**\n",
    "- When referencing literature or research findings, use the format: ***According to the literature, [finding]*** or ***Research indicates that [finding]*** or ***Studies show that [finding]***\n",
    "- Make all literature citations bold and italic using ***text*** format\n",
    "- This will help patients easily identify evidence-based information\n",
    "- Example: ***According to recent studies, patients with moderate diabetic retinopathy have a 25% risk of progression within one year***\n",
    "\n",
    "When referencing the literature, mention the source papers to add credibility to your analysis.\"\"\"\n",
    "\n",
    "    return self._call_gpt_with_enhanced_prompt(enhanced_prompt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VQA integration and enhanced prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def analyze_retinal_image_and_heatmap(original_image, heatmap_figure, prediction_results, patient_age=None, diabetes_duration=None):\n",
    "\"\"\"Analyze retinal image with heatmap using GPT-4o-mini vision capabilities enhanced with RAG\"\"\"\n",
    "api_url = \"https://api.openai.com/v1/chat/completions\"\n",
    "api_key = get_api_key()\n",
    "\n",
    "if not api_key:\n",
    "    raise ValueError(\"API key not found\")\n",
    "\n",
    "# Initialize RAG service\n",
    "rag = initialize_rag_service()\n",
    "\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {api_key}\",\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "\n",
    "# Encode images to base64\n",
    "original_b64 = encode_image_to_base64(original_image)\n",
    "heatmap_b64 = encode_image_to_base64(heatmap_figure)\n",
    "\n",
    "# Construct detailed prompt\n",
    "patient_info = \"\"\n",
    "if patient_age and diabetes_duration:\n",
    "    patient_info = f\"\\nPatient Information:\\n- Age: {patient_age} years\\n- Duration of diabetes: {diabetes_duration} years\\n\"\n",
    "\n",
    "# Get relevant medical literature context using RAG\n",
    "medical_context = \"\"\n",
    "if rag:\n",
    "    try:\n",
    "        search_query = f\"diabetic retinopathy grade {prediction_results['value']} {prediction_results['class']} analysis heatmap fundus examination\"\n",
    "        medical_context = rag.get_relevant_medical_context(search_query, max_context_length=2000)\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: Could not retrieve medical context: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "advanced prompting engineering for medical rag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "python\n",
    "# Enhanced prompt with medical literature context\n",
    "    base_prompt = f\"\"\"You are an expert ophthalmologist AI assistant analyzing retinal images for diabetic retinopathy.\n",
    "\n",
    "{patient_info}\n",
    "AI Model Results:\n",
    "- Predicted Class: {prediction_results['class']}\n",
    "- Severity Grade: {prediction_results['value']}\n",
    "- Confidence: {prediction_results['probability']:.2%}\n",
    "\n",
    "I'm showing you two images:\n",
    "1. The original retinal fundus photograph\n",
    "2. A GradCAM heatmap visualization showing which areas the AI model focused on for its prediction\"\"\"\n",
    "\n",
    "    if medical_context:\n",
    "        enhanced_prompt = f\"\"\"{base_prompt}\n",
    "\n",
    "RELEVANT MEDICAL LITERATURE:\n",
    "{medical_context}\n",
    "\n",
    "Please provide a comprehensive analysis that incorporates insights from the current medical literature above, including:\n",
    "\n",
    "1. **Clinical Assessment**: Explain what the AI prediction means in medical terms, referencing relevant literature\n",
    "2. **Heatmap Analysis**: Describe what the highlighted areas represent and their clinical significance based on current research\n",
    "3. **Key Findings**: Identify specific retinal features visible in the image that support the diagnosis, citing literature when relevant\n",
    "4. **Evidence-Based Patient Explanation**: Provide a clear, patient-friendly explanation supported by research findings\n",
    "5. **Current Guidelines Recommendations**: Suggest appropriate next steps based on the latest clinical guidelines\n",
    "6. **Monitoring Protocol**: Advise on follow-up frequency and warning signs based on evidence-based practices\n",
    "\n",
    "**IMPORTANT FORMATTING INSTRUCTIONS:**\n",
    "- When referencing literature or research findings, use the format: ***According to the literature, [finding]*** or ***Research indicates that [finding]*** or ***Studies show that [finding]***\n",
    "- Make all literature citations bold and italic using ***text*** format\n",
    "- This will help patients easily identify evidence-based information\n",
    "- Example: ***According to recent studies, GradCAM highlighted areas typically indicate microaneurysms which are early signs of diabetic retinopathy***\n",
    "\n",
    "When relevant, cite the medical literature to support your analysis and recommendations.\"\"\"\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "QA enhancement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def answer_retinal_question(question, context_analysis, prediction_results, patient_age=None, diabetes_duration=None):\n",
    "\"\"\"Answer specific questions about the retinal analysis using RAG-enhanced responses\"\"\"\n",
    "\n",
    "# Initialize RAG service\n",
    "rag = initialize_rag_service()\n",
    "\n",
    "# Prepare patient context\n",
    "patient_info = \"\"\n",
    "if patient_age and diabetes_duration:\n",
    "    patient_info = f\"Patient: {patient_age} years old, diabetes for {diabetes_duration} years. \"\n",
    "\n",
    "patient_context = f\"{patient_info}Current AI Results: {prediction_results['class']} (Grade {prediction_results['value']}, {prediction_results['probability']:.2%} confidence)\"\n",
    "\n",
    "# Use RAG-enhanced question answering if available\n",
    "if rag:\n",
    "    try:\n",
    "        return rag.enhanced_question_answering(\n",
    "            question=question,\n",
    "            previous_analysis=context_analysis,\n",
    "            patient_context=patient_context,\n",
    "            prediction_results=prediction_results\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: RAG-enhanced answering failed, falling back to basic method: {e}\")\n",
    "\n",
    "# Fallback to original method# ... [existing fallback code]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "retinal_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
